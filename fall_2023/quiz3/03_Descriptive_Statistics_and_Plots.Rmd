---
title: "Descriptive Statistics and Plots"
output: 
  learnr::tutorial:
    progressive: TRUE
    allow_skip: FALSE
runtime: shiny_prerendered
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
library(learnr)
library(tidyverse)
library(knitr)
library(ggmosaic)
library(praise)
library(utils)
library(datasets)
library(dplyr)
tutorial_options(exercise.eval = TRUE, exercise.reveal_solution = FALSE)
gradethis::gradethis_setup(
  pass.praise = TRUE,
  fail.encourage = TRUE,
  fail.hint = TRUE
)

```

## Overview

Tasks: 

-   Work through this document

Learning outcomes: 

1. Learn about Rmarkdown

2.  Learn how to perform routine data wrangling tasks with `dplyr` core functions: `filter`, `select`, `mutate`, `arrange`, `transmute`, `summarise`

3.  Pipe `%>%` these operations together.

4.  Be able to suggest improvements to basic graphs to improve readability and accurate communication

5.  Explain the idea of mapping data onto aesthetics, and the use of different `geoms`

6.  Match common plots to common data type.

## What is rmarkdown

1. Take this [short tutorial](https://rmarkdown.rstudio.com/lesson-1.html) from Rstudio about the basics of R markdown (you can go up until "Notebooks" but no need to work through the final 4 steps starting at ("slide presentations").

2. Here is a very useful [R Markdown cheatsheet](https://rmarkdown.rstudio.com/lesson-15.html).

No need to watch these now, but try to watch them before you start working on LA1.
(these are also posted in the assignment instructions)

* [What is R Markdown](https://capture.dropbox.com/8iVT7yksrItSTpkW)
* [Using R markdown in Rstudio](https://www.youtube.com/watch?v=DNS7i2m4sB0&feature=youtu.be)
* [Overview of R markdown](https://www.youtube.com/watch?v=mcTB7h9lpCg&feature=youtu.be)







## Reading in data and dealing with missing data

### Read in data

You can import many types of data in R. If you want to see which file types are possible to read in from base R, type "read" in the console and then hit tab. That will show you all the various types of read functions for different file types inherent to base R.

Here, we'll be using read.csv which reads... csv files.

```{r, echo=T, eval=F}
<<<<<<< Updated upstream

titanicdata <- read.csv("~/Documents/GitHub/B215_Lessons/fall_2022_materials/lab3/data/titanic.csv", stringsAsFactors = TRUE)
```


```{r setupnum}

titanicdata <- read.csv("~/Documents/GitHub/B215_Lessons/fall_2022_materials/lab3/data/titanic.csv", stringsAsFactors = TRUE)
titanicdata2<-na.omit(titanicdata)


```

Notice that we put quotation marks around the name of the csv file we're reading in. This is because it comes from outside of the environment, it is the same logic as when we use quotation marks for installing packages.

### Preliminary Data Examination

Sometimes, real world data sucks. It's missing entries, or it mixes data class types (e.g., a column that appears to be numeric, but is actually a sneaky character vector). For that reason, you always should inspect your data before you do any stats. For small files, view("r object") can be used, but for larger files, opening an r object can be prohibitively slow. You have already learned a function to call the first six rows of a dataset: head. Call it here and inspect the object titanicdata. This data both refers to the titanic and is, itself, titanic and therefore head is appropriate.
```{r examplenum, exercise = TRUE, exercise.setup = "setupnum"}
                    
```


```{r examplenum-solution}
head(titanicdata)

```

```{r examplenum-check}
grade_this_code()
```

## Summary statistics and missing data!

Now look at age by selecting the column `age` in the `titanicdata` object and printing out that column:
```{r examplenum1, exercise = TRUE, exercise.setup = "setupnum"}
                    
```


```{r examplenum1-solution}
print(titanicdata$age)

```

```{r examplenum1-check}
grade_this_code()
```

If you look through the results, you will see that most individuals have numbers in this list, but some have NA. These NAs are the people for which we do not have age information.

By the way, the `titanic.csv` file simply has nothing in the places where there is missing data. When R loaded it, it replaced the empty spots with NA automatically.

We have already seen in lab 2 how to calculate the mean of a vector of data using `mean()`. Unfortunately, if there are missing data we need to tell R how to deal with it.

A (somewhat annoying) quirk of R is that if we try to take the mean of a list of numbers that include missing data, we get an NA for the result!


```{r}
mean(titanicdata$age)
```

To get the mean of all the numbers that we do have, we have to add an option to the mean() function. This option is `na.rm = TRUE`:


```{r}
mean(titanicdata$age, na.rm = T)
```

Many other functions have this "na.rm = T" option, but for those that don't, you will have to do some data cleaning, which we will learn how to do shortly.

Try this with the function for standard deviation: sd()

```{r examplenum2, exercise = TRUE, exercise.setup = "setupnum"}
                    
```


```{r examplenum2-solution}
sd(titanicdata$age, na.rm = T)

```

```{r examplenum2-check}
grade_this_code()
```

SD is one way to measure variance and deviation but there are others!

Try calculating the variance of the age data using the implemtation in r: var()
```{r examplenum3, exercise = TRUE, exercise.setup = "setupnum"}
                    
```


```{r examplenum3-solution}
var(titanicdata$age, na.rm = T)

```

```{r examplenum3-check}
grade_this_code()
```

If you notice, variance is just SD squared. Or. SD is just variance square rooted.

Other metrics of variation include the coefficient of variation. Surprisingly, there is no standard function in R to calculate the coefficient of variation. You can do this yourself, though, directly from the definition:

```{r}
100 * sd(titanicdata$age, na.rm = TRUE) / mean(titanicdata$age, na.rm = TRUE) 

```

Make sure you understand the command above before continuing!

Other metrics include range and interquartile range which are the differnece between the max and the min points in the data and the third quartile and first quartile in the data respectively. You can call these functions as range() and IQR() in the exact same format as mean() and sd().

### Missing data

Lets say you are trying to do a statistical test which lacks na. rm capabilities? Well, it's pretty simple:
```{r}
titanicdata2<-na.omit(titanicdata)
```

We can confirm that the missing rows have been deleted by comparing the number of rows in titanicdata2 with titanic data:
```{r}
nrow(titanicdata)-nrow(titanicdata2)
```

680 rows with missing data! But did this function actually remove all the rows with missing data or did it mess up? 

Well, three functions are useful for us to decide. length, which returns the number of entries, which, and is.na, which returns a logical statement stating whether any entry in the input is NA.

Try testing whether there are any NAs in titanicdata$age (which, becuase we know there are, should return TRUE)
```{r examplenum4, exercise = TRUE, exercise.setup = "setupnum"}
                    
```


```{r examplenum4-solution}
is.na(titanicdata$age)

```

```{r examplenum4-check}
grade_this_code()
```

Now, since we know that there are NAs in the age column, try finding out which rows in titanicdata contain NAs
```{r examplenum5, exercise = TRUE, exercise.setup = "setupnum"}
                    
```


```{r examplenum5-solution}
which(is.na(titanicdata$age))

```

```{r examplenum5-check}
grade_this_code()
```

This should return a big list of row numbers and, finally, we can take the length of this result and if it equals 680, we will know that na.omit worked:
```{r examplenum6, exercise = TRUE, exercise.setup = "setupnum"}
                    
```


```{r examplenum6-solution}
length(which(is.na(titanicdata$age)))

```

```{r examplenum6-check}
grade_this_code()
```

You might be wondering why we took the time to check where precisely the the missing data is located, besides to check the accuracy of na.omit. It is important to know where your missing data is because if the missing data is particularly prevalent in one variable more than another, or severely limits the pool of usable data, it can impact the accuracy of the data analysis performed. There is not a hard and fast rule about what level of missing data is acceptable, but it is important to document the limitations of our data so we can account for those limitations in our analysis (whether it be choosing the most appropriate plot or statistical test or simply disclosing the limitations of your study upon publication). No data is ever going to be perfect, especially when working in biology, but is is important to know the flaws in your analyses intimately so you can mitigate them to the best of your ability.

## Soft Intro to the Tidyverse

## Exploring the data

Now that we've familiarized ourselves with the tidyverse, let's return to the titanic data to try out our skills. The titanic data has age, sex, class of the passenger and whether or not they survived. The summarize function is super useful here for analyzing the different factors that are correlated with a passenger's chance of survival. In this example, we will explore age and survival rate. This is how you'd use summarize to group by if someone survived, and get the mean of their ages. Print the new data frame to see.


```{r examplenum7, exercise = TRUE, exercise.setup = "setupnum"}
 mean_ages <- titanicdata2 %>%
  group_by(survive) %>%
  summarise(
    mean_age = mean(age)
  )
                   
```



```{r examplenum7-solution}

class_survive <- titanic %>%
  group_by(passenger_class) %>%
  summarise(
    survived = sum(survive == "yes"),
    died = sum(survive == "no")
  )



```

```{r examplenum7-check}
grade_this_code()
```



Lets compare survival odds between classes. Use the group_by() function to group the passengers by class. The summarize() function lets you create a new data frame to look at summary statistics from your original dataset. Dplyr lets you chain commands together using  %>%. Let's use the filtered data that doesn't have any missing values. 
(you'll have two arguments inside the summarise function)


```{r examplenum8, exercise = TRUE, exercise.setup = "setupnum"}
                    
```



```{r examplenum8-solution}

class_survive <- titanic %>%
  group_by(passenger_class) %>%
  summarise(
    survived = sum(survive == "yes"),
    died = sum(survive == "no")
  )



```

```{r examplenum8-check}
grade_this_code()
```


## Working with real data



Now we are going to practice working with an actual data set. We will be using one from the datasets package called chickweights. It's from an experiment on the effect of diet on early growth of chicks. If you want to learn more about the dataset type ??chickweights into your console. 

### Lets look at the data
The datasets package already has the data stored as a data frame. If it wasn't you could call data.frame to turn it into one. Rename the data chicks by assigning the code already loaded to that name. 
It's long, so we don't want to print the whole thing. Use a specific function to call just the first 6 rows.

```{r chicks1, exercise = TRUE}
datasets::ChickWeight

```


```{r chicks1-solution}
chicks<-datasets::ChickWeight
head(chicks)
```

```{r chicks1-check}
grade_this_code()
```

### Analyzing the data
Lets see which diet worked best! This data shows us the same chicken at multiple times. If we only want to see the final outcome, we can filter for the final weight. Using the dplyr filter function to select only chicks with time 21.
name this resulting dataframe FinalChicks. Then print it. 
```{r setupchicks}
chicks<-datasets::ChickWeight
FinalChicks<-filter(chicks, Time == "21")


```



```{r chicks2, exercise = TRUE, exercise.setup = "setupchicks"}

```


```{r chicks2-solution}
FinalChicks<-filter(chicks, Time == "21")
print(FinalChicks)
```

```{r chicks2-check}
grade_this_code()
```


Now lets get the mean for each diet. Use the pattern below calculate the mean weight for the chicks in each of the 4 diets. 

```{r chicks3, exercise = TRUE, exercise.setup = "setupchicks"}
diet1<-filter(FinalChicks, Diet == "1")
mean(diet1$weight)

```


```{r chicks3-solution}
diet1<-filter(FinalChicks, Diet == "1")
mean(diet1$weight)

diet2<-filter(FinalChicks, Diet == "2")
mean(diet2$weight)

diet3<-filter(FinalChicks, Diet == "3")
mean(diet3$weight)

diet4<-filter(FinalChicks, Diet == "4")
mean(diet4$weight)

```

```{r chicks3-check}
grade_this_code()
```



Isn't that a lot of work to get 4 simple means? Let's go over how to do this with dyplr. First group by diet, then summarise to find the mean weight. Then print the result

```{r chicks4, exercise = TRUE, exercise.setup = "setupchicks"}


```


```{r chicks4-solution}
avg_chick_wgts<- FinalChicks %>%
group_by(Diet) %>%
summarize(mean_weight = mean(weight))

print(avg_chick_wgts)
```

```{r chicks4-check}
grade_this_code()
```


There are other dplyr commands that are very useful, and they follow the same basic structure. 



Now let's graph the chicks. We are going to make a basic ggplot, using geom_jitter. We don't just want to use our means because that tells us less than our original data. so using FinalChicks, graph diet on the x axis and weight on the y axis. 

```{r chicks5, exercise = TRUE, exercise.setup = "setupchicks"}


```


```{r chicks5-solution}
ggplot(FinalChicks, aes(x=Diet, y=weight))+geom_jitter()
```

```{r chicks5-check}
grade_this_code()
```




## The quiz

Let us analyze some beautiful black cherry trees. Load the dataset trees from the package datasets, name it trees, and call head on it


```{r trees1, exercise = TRUE}
trees<-datasets::trees

```


```{r trees1-solution}
trees<-datasets::trees
head(trees)
```

```{r trees1-check}
grade_this_code()
```

lets make a new column called "ratio" where we divide the girth of the tree by its height. We will use the mutate function. Use mutate like summarise, and create the new column in a data frame called tree_ratios. Then print it.


```{r trees2, exercise = TRUE}


```


```{r trees2-solution}
tree_ratios <- trees %>% 
  mutate(ratio = Girth / Height)
print(tree_ratios)
```

```{r trees2-check}
grade_this_code()
```


Now that we have our ratios, we can see that they range from 0.118 to 0.236. Lets sort these trees into 2 types of tree. any tree under or equal to 0.17 is to be called "skinny legeand" and anytree over is to be call "thicc". Call this data frame tree_types and the new column tree_judgement You're going to use the case_when function inside the mutate function.  

```{r setuptrees}

trees<-datasets::trees
tree_ratios <- trees %>% 
  mutate(ratio = Girth / Height)

```



```{r trees3, exercise = TRUE, setup="setuptrees"}



```


```{r trees3-solution}
trees_types <- trees_with_type_and_ratio %>%
  mutate(tree_judgement = case_when(
    ratio <= 0.17 ~ "skinny legend",
    ratio > 0.17 ~ "thicc"
  ))

```

```{r tree3-check}
grade_this_code()
```



I have typed the word tree so many times while making this that it doesn't seem like a word anymore. tree. tree. silly word right? seems like its missing something. 





READ FIRST:

* as before, go to your browser and select "print" to keep a pdf copy of your work.
* use your username from your institutional email as your username
* use b215f23 as password
* this will close the quiz and take you back to Posit cloud. Click on the little red "stop" icon in the console to stop the quiz for good.
* in the files pane, you will see a file called "quiz1_record.txt". Select it and then go to the little wheel and click "export". 
* upload that file and your PDF copy into the lab1-quiz on Moodle!
* you're done!

```{r, echo=F}
submitr::login_controls()
```
